# -*- coding: utf-8 -*-
"""CarciLens.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16jWQ_UjKVMuOZfXnzg4IQi_QvpuuG2DH

**Importing Dependencies**
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import sklearn.datasets
from sklearn.model_selection import train_test_split

"""**Data Collection & Processing**"""

# Load the breast cancer dataset from sklearn
breast_cancer_dataset = sklearn.datasets.load_breast_cancer()
print("Dataset loaded successfully!")

# Convert the dataset into a pandas dataFrame
data_frame = pd.DataFrame(breast_cancer_dataset.data, columns=breast_cancer_dataset.feature_names)

# Add 'label' column to the dataframe
data_frame['label'] = breast_cancer_dataset.target

# Print the first 5 rows of the dataframe
data_frame.head()
# Print last 5 rows of the dataframe
data_frame.tail()

# Number of rows and columns in the dataset.
data_frame.shape
# Getting information about the data.
data_frame.info()

# Checking for missing values.
data_frame.isnull().sum()

# Important statistical measures about the data.
data_frame.describe()

# Checking the distribution of Target Variable.
data_frame['label'].value_counts()

"""1 - Benign

0 - Malignant
"""

data_frame.groupby('label').mean()

# Separate Features (X) and Target (Y)
X = data_frame.drop(columns='label', axis=1)
Y = data_frame['label']

print(X)

print(Y)

"""**Splitting the data into Training & Testing**"""

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)

print(X.shape, X_train.shape, X_test.shape)

"""**Standardization of Data**"""

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train_std = scaler.fit_transform(X_train)
X_test_std = scaler.transform(X_test)

"""**Building the Neural Network**"""

# Importing tensorflow and keras
import tensorflow as tf
tf.random.set_seed(3)
from tensorflow import keras

# Setting up the layers of Neural Network
model = keras.Sequential([
                          keras.Input(shape=(30,)),  # Input layer
                          keras.layers.Flatten(),
                          keras.layers.Dense(20, activation='relu'),
                          keras.layers.Dense(2, activation='sigmoid')
])

# Compiling the Neural Network

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

"""**Network Training**"""

history = model.fit(X_train_std, Y_train, validation_split=0.1, epochs=10)

"""**Visualizing Accuracy and Loss**"""

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['training data', 'validation data'], loc = 'lower right')

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['training data', 'validation data'], loc = 'upper right')

"""**Accuracy of the model on test data**"""

loss, accuracy = model.evaluate(X_test_std, Y_test)
print(accuracy)

print(X_test_std.shape)
print(X_test_std[0])

Y_pred = model.predict(X_test_std) # model.predict() gives the prediction probability of each class for that data point
print(Y_pred.shape)
print(Y_pred[0])

print(X_test_std)

print(Y_pred)

# argmax function

my_list = [0.25, 0.56]

index_of_max_value = np.argmax(my_list)
print(my_list)
print(index_of_max_value)

# Converting the prediction probability to class labels

Y_pred_labels = [np.argmax(i) for i in Y_pred]
print(Y_pred_labels)

"""**Building a Predictive System**"""

# Convert input data to a pandas DataFrame and retain the same column names as training data
input_data_as_dataframe = pd.DataFrame(input_data_as_numpy_array.reshape(1, -1), columns=X.columns)

# Standardize the input data using the fitted scaler
input_data_std = scaler.transform(input_data_as_dataframe)

# Make predictions with the standardized data
prediction = model.predict(input_data_std)
print(prediction)

prediction_label = [np.argmax(prediction)]
print(prediction_label)

if(prediction_label[0] == 0):
    print('The tumor is Malignant.')
else:
    print('The tumor is Benign.')